This repository explores the collaborative dynamics of advanced large language models (LLMs) such as GPT-4-0125-preview, Meta-LLaMA-3-70B-Instruct, Claude-3-Opus, and Gemini-1.5-Flash in generating and answering complex, PhD-level statistical questions without ground-truth answers. By leveraging inter-model consensus mechanisms, statistical methods like chi-square tests, Fleiss' Kappa, and confidence interval analysis, we quantify the reliability and precision of their outputs. Key findings reveal that models like Claude and GPT-4 demonstrate superior reliability and consistency, while Gemini and LLaMA exhibit greater variability. This work highlights the potential of collaborative AI systems to enhance response reliability and provides insights into autonomous, cooperative reasoning in large language models.
